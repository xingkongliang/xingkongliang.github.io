<!DOCTYPE html>
<html lang="default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.starlg.cn","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="行人检测（Pedestrian Detection）论文整理，包含论文链接和代码地址。">
<meta property="og:type" content="article">
<meta property="og:title" content="行人检测（Pedestrian Detection）论文整理">
<meta property="og:url" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/index.html">
<meta property="og:site_name" content="Tianliang">
<meta property="og:description" content="行人检测（Pedestrian Detection）论文整理，包含论文链接和代码地址。">
<meta property="og:locale">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/CVPR19_CSP_Adaptive_NMS.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/CVPR19_CSP_PedestrianDetection.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/CVPR19_SSA-CNN.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1533980426553.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1533980383783.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/ECCV2018-Bi-box_Regression_2.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/ECCV2018-Graininess-Aware_Deep_Learning.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/ECCV2018-Occlusion-aware_R-CNN.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1533979932529.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1533980803719.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1533980145178.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1528195001788.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1537261066815.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1533980559400.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1528194369562.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1528194560698.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1528194591022.png">
<meta property="og:image" content="http://cvlab.cse.msu.edu/images/teasers/pedestrian-intro.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1528195250768.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1537260670049.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1537260505221.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1537260310332.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1537260117170.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1534569661113.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1517407508293.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1534570096814.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/1534569869602.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/eurocity-01.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/eurocity-02.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/crowdhuman-20190918-01.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/crowdhuman-20190918-02.png">
<meta property="og:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/crowdhuman-20190918-03.png">
<meta property="article:published_time" content="2018-08-17T01:26:22.000Z">
<meta property="article:modified_time" content="2022-05-30T14:16:36.000Z">
<meta property="article:author" content="Tianliang Zhang">
<meta property="article:tag" content="Pedestrian Detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/CVPR19_CSP_Adaptive_NMS.png">


<link rel="canonical" href="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"default","comments":true,"permalink":"https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/","path":"2018/08/17/Pedestrian-Detection-Sources/","title":"行人检测（Pedestrian Detection）论文整理"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>行人检测（Pedestrian Detection）论文整理 | Tianliang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PLDYM9BF5R"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-PLDYM9BF5R","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tianliang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="https://www.starlg.cn/TianliangZhang/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5github%E5%9C%B0%E5%9D%80"><span class="nav-number">1.</span> <span class="nav-text">同步github地址</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E7%A7%91%E7%A0%94%E5%B7%A5%E4%BD%9C%E8%80%85"><span class="nav-number">2.</span> <span class="nav-text">相关科研工作者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%80%E6%94%BE%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="nav-number">3.</span> <span class="nav-text">开放的代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#paper-list"><span class="nav-number">4.</span> <span class="nav-text">Paper List</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BA%E6%96%87"><span class="nav-number">5.</span> <span class="nav-text">论文</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2019-oral-adaptive-nms-refining-pedestrian-detection-in-a-crowd"><span class="nav-number">5.1.</span> <span class="nav-text">[CVPR-2019
oral] Adaptive NMS: Refining Pedestrian Detection in a Crowd</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2019-high-level-semantic-feature-detectiona-new-perspective-for-pedestrian-detection"><span class="nav-number">5.2.</span> <span class="nav-text">[CVPR-2019]
High-level Semantic Feature Detection:A New Perspective for Pedestrian
Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2019-ssa-cnn-semantic-self-attention-cnn-for-pedestrian-detection"><span class="nav-number">5.3.</span> <span class="nav-text">[CVPR-2019]
SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2019-pedestrian-detection-in-thermal-images-using-saliency-maps"><span class="nav-number">5.4.</span> <span class="nav-text">[CVPR-2019]
Pedestrian Detection in Thermal Images using Saliency Maps</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tip-2018-too-far-to-see-not-really-pedestrian-detection-with-scale-aware-localization-policy"><span class="nav-number">5.5.</span> <span class="nav-text">[TIP-2018]
Too Far to See? Not Really: Pedestrian Detection with Scale-Aware
Localization Policy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transactions-on-multimedia-201%EF%BC%98-scale-aware-fast-r-cnn-for-pedestrian-detection"><span class="nav-number">5.6.</span> <span class="nav-text">[Transactions
on Multimedia-201８] Scale-Aware Fast R-CNN for Pedestrian
Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eccv-2018-bi-box-regression-for-pedestrian-detection-and-occlusion-estimation"><span class="nav-number">5.7.</span> <span class="nav-text">[ECCV-2018]
Bi-box Regression for Pedestrian Detection and Occlusion Estimation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eccv-2018-learning-efficient-single-stage-pedestrian-detectors-by-asymptotic-localization-fitting"><span class="nav-number">5.8.</span> <span class="nav-text">[ECCV-2018]
Learning Efficient Single-stage Pedestrian Detectors by Asymptotic
Localization Fitting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eccv-2018-graininess-aware-deep-feature-learning-for-pedestrian-detection"><span class="nav-number">5.9.</span> <span class="nav-text">[ECCV-2018]
Graininess-Aware Deep Feature Learning for Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eccv-2018-occlusion-aware-r-cnn-detecting-pedestrians-in-a-crowd"><span class="nav-number">5.10.</span> <span class="nav-text">[ECCV-2018]
Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eccv-2018-small-scale-pedestrian-detection-based-on-somatic-topology-localization-and-temporal-feature-aggregation"><span class="nav-number">5.11.</span> <span class="nav-text">[ECCV-2018]
Small-scale Pedestrian Detection Based on Somatic Topology Localization
and Temporal Feature Aggregation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2018-improving-occlusion-and-hard-negative-handling-for-single-stage-pedestrian-detectors"><span class="nav-number">5.12.</span> <span class="nav-text">[CVPR-2018]
Improving Occlusion and Hard Negative Handling for Single-Stage
Pedestrian Detectors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2018-occluded-pedestrian-detection-through-guided-attention-in-cnns"><span class="nav-number">5.13.</span> <span class="nav-text">[CVPR-2018]
Occluded Pedestrian Detection Through Guided Attention in CNNs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2018-repulsion-loss-detecting-pedestrians-in-a-crowd"><span class="nav-number">5.14.</span> <span class="nav-text">[CVPR-2018]
Repulsion Loss: Detecting Pedestrians in a Crowd</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tpami-2017-jointly-learning-deep-features-deformable-parts-occlusion-and-classification-for-pedestrian-detection"><span class="nav-number">5.15.</span> <span class="nav-text">[TPAMI-2017]
Jointly Learning Deep Features, Deformable Parts, Occlusion and
Classification for Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bmvc-2017-pcn-part-and-context-information-for-pedestrian-detection-with-cnns"><span class="nav-number">5.16.</span> <span class="nav-text">[BMVC-2017]
PCN: Part and Context Information for Pedestrian Detection with
CNNs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2017-citypersons-a-diverse-dataset-for-pedestrian-detection"><span class="nav-number">5.17.</span> <span class="nav-text">[CVPR-2017]
CityPersons: A Diverse Dataset for Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2017-learning-cross-modal-deep-representations-for-robust-pedestrian-detection"><span class="nav-number">5.18.</span> <span class="nav-text">[CVPR-2017]
Learning Cross-Modal Deep Representations for Robust Pedestrian
Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2017-what-can-help-pedestrian-detection"><span class="nav-number">5.19.</span> <span class="nav-text">[CVPR-2017] What
Can Help Pedestrian Detection?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tpami-2017-towards-reaching-human-performance-in-pedestrian-detection"><span class="nav-number">5.20.</span> <span class="nav-text">[TPAMI-2017]
Towards Reaching Human Performance in Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#iccv-2017-multi-label-learning-of-part-detectors-for-heavily-occluded-pedestrian-detection"><span class="nav-number">5.21.</span> <span class="nav-text">[ICCV-2017]
Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian
Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#iccv-2017illuminating-pedestrians-via-simultaneous-detection-segmentation"><span class="nav-number">5.22.</span> <span class="nav-text">[ICCV-2017]Illuminating
Pedestrians via Simultaneous Detection &amp; Segmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2016-semantic-channels-for-fast-pedestrian-detection"><span class="nav-number">5.23.</span> <span class="nav-text">[CVPR-2016]
Semantic Channels for Fast Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2016-how-far-arewe-from-solving-pedestrian-detection"><span class="nav-number">5.24.</span> <span class="nav-text">[CVPR-2016]
How Far areWe from Solving Pedestrian Detection?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#iccv-2015-deep-learning-strong-parts-for-pedestrian-detection"><span class="nav-number">5.25.</span> <span class="nav-text">[ICCV-2015]
Deep Learning Strong Parts for Pedestrian Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2013-joint-deep-learning-for-pedestrian-detection-wanli"><span class="nav-number">5.26.</span> <span class="nav-text">[CVPR-2013]
Joint Deep Learning for Pedestrian Detection Wanli</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2012-a-discriminative-deep-model-for-pedestrian-detection-with-occlusion-handling"><span class="nav-number">5.27.</span> <span class="nav-text">[CVPR-2012]
A Discriminative Deep Model for Pedestrian Detection with Occlusion
Handling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cvpr-2010-multi-cue-pedestrian-classification-with-partial-occlusion-handling"><span class="nav-number">5.28.</span> <span class="nav-text">[CVPR-2010]
Multi-Cue Pedestrian Classification With Partial Occlusion Handling</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A1%8C%E4%BA%BA%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">6.</span> <span class="nav-text">行人检测数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#citypersons"><span class="nav-number">6.1.</span> <span class="nav-text">CityPersons</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#caltech"><span class="nav-number">6.2.</span> <span class="nav-text">Caltech</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kitti"><span class="nav-number">6.3.</span> <span class="nav-text">KITTI</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#eurocity"><span class="nav-number">6.4.</span> <span class="nav-text">EuroCity</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#crowdhuman"><span class="nav-number">6.5.</span> <span class="nav-text">CrowdHuman</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83"><span class="nav-number">7.</span> <span class="nav-text">性能比较</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Tianliang Zhang"
      src="https://avatars1.githubusercontent.com/u/8827798?v=3&s=460">
  <p class="site-author-name" itemprop="name">Tianliang Zhang</p>
  <div class="site-description" itemprop="description">Writing is the best form of thinking!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/xingkongliang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xingkongliang" rel="noopener me" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:tianliangjay@gmail.com" title="E-Mail → mailto:tianliangjay@gmail.com" rel="noopener me" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://www.zhihu.com/people/xingkong_liang" title="知乎 → http:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;xingkong_liang" rel="noopener me" target="_blank">知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://weibo.com/1863221531" title="微博 → http:&#x2F;&#x2F;weibo.com&#x2F;1863221531" rel="noopener me" target="_blank"><i class="weibo fa-fw"></i>微博</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          Links
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://codesolve.online/" title="https:&#x2F;&#x2F;codesolve.online" rel="noopener" target="_blank">LeetCode解题指南</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://easyielts.cn/" title="https:&#x2F;&#x2F;easyielts.cn" rel="noopener" target="_blank">雅思题库和范例</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.starlg.cn/2018/08/17/Pedestrian-Detection-Sources/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/8827798?v=3&s=460">
      <meta itemprop="name" content="Tianliang Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tianliang">
      <meta itemprop="description" content="Writing is the best form of thinking!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="行人检测（Pedestrian Detection）论文整理 | Tianliang">
      <meta itemprop="description" content="行人检测（Pedestrian Detection）论文整理，包含论文链接和代码地址。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          行人检测（Pedestrian Detection）论文整理
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2018-08-17 11:26:22" itemprop="dateCreated datePublished" datetime="2018-08-17T11:26:22+10:00">2018-08-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-31 00:16:36" itemprop="dateModified" datetime="2022-05-31T00:16:36+10:00">2022-05-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Pedestrian-Detection/" itemprop="url" rel="index"><span itemprop="name">Pedestrian Detection</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

            <div class="post-description">行人检测（Pedestrian Detection）论文整理，包含论文链接和代码地址。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="同步github地址">同步github地址</h2>
<p>本文档同步至github:<a
href="https://github.com/xingkongliang/Pedestrian-Detection">here</a></p>
<h2 id="相关科研工作者">相关科研工作者</h2>
<ul>
<li><a
href="https://scholar.google.com/citations?user=a8Y2OJMAAAAJ&amp;hl=zh-CN">Piotr
Dollár scholar</a></li>
<li><a href="https://pdollar.github.io/">Piotr Dollár homepage</a></li>
<li><a
href="https://scholar.google.com/citations?hl=zh-CN&amp;user=pOSMWfQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">张姗姗
scholar</a></li>
<li><a
href="https://sites.google.com/site/shanshanzhangshomepage/">张姗姗
homepage</a></li>
<li><a
href="https://scholar.google.com/citations?user=pw_0Z_UAAAAJ&amp;%20hl=en">欧阳万里
scholar</a></li>
<li><a href="http://www.ee.cuhk.edu.hk/~wlouyang/">欧阳万里
homepage</a></li>
<li><a href="https://liuwei16.github.io/">Liu Wei homepage</a></li>
</ul>
<h2 id="开放的代码">开放的代码</h2>
<ul>
<li><p><a
href="https://github.com/Leotju/MGAN"><strong>Leotju/MGAN</strong></a>
[ICCV-2019] Mask-Guided Attention Network for Occluded Pedestrian
Detection [<a
href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Pang_Mask-Guided_Attention_Network_for_Occluded_Pedestrian_Detection_ICCV_2019_paper.pdf">paper</a>]</p></li>
<li><p><a
href="https://github.com/lw396285v/CSP-pedestrian-detection-in-pytorch"><strong>lw396285v/CSP-pedestrian-detection-in-pytorch
非官方实现</strong></a> [CVPR-2019] High-level Semantic Feature
Detection:A New Perspective for Pedestrian Detection [<a
href="https://arxiv.org/abs/1904.02948">paper</a>]</p></li>
<li><p><a
href="https://github.com/liuwei16/CSP"><strong>liuwei16/CSP</strong></a>
[CVPR-2019] High-level Semantic Feature Detection:A New Perspective for
Pedestrian Detection [<a
href="https://arxiv.org/abs/1904.02948">paper</a>]</p></li>
<li><p><a
href="https://github.com/liuwei16/ALFNet"><strong>liuwei16/ALFNet</strong></a>
[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by
Asymptotic Localization Fitting</p></li>
<li><p><a
href="https://github.com/rainofmine/Bi-box_Regression"><strong>rainofmine/Bi-box_Regression
非官方实现</strong></a> [ECCV-2018] Bi-box Regression for Pedestrian
Detection and Occlusion Estimation</p></li>
<li><p><a
href="https://github.com/rainofmine/Repulsion_Loss"><strong>rainofmine/Repulsion_Loss
非官方实现</strong></a> [CVPR-2018] Repulsion Loss: Detecting
Pedestrians in a Crowd</p></li>
<li><p><a
href="https://github.com/garrickbrazil/SDS-RCNN"><strong>garrickbrazil/SDS-RCNN</strong></a>
[ICCV-2017] Illuminating Pedestrians via Simultaneous Detection &amp;
Segmentation</p></li>
<li><p><a
href="https://github.com/zhangliliang/RPN_BF"><strong>zhangliliang/RPN_BF</strong></a>
[ECCV-2016] Is Faster R-CNN Doing Well for Pedestrian
Detection?</p></li>
</ul>
<h2 id="paper-list">Paper List</h2>
<ul>
<li>[ICCV-2019] Semi-Supervised Pedestrian Instance Synthesis and
Detection With Mutual Reinforcement [<a
href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Semi-Supervised_Pedestrian_Instance_Synthesis_and_Detection_With_Mutual_Reinforcement_ICCV_2019_paper.pdf">paper</a>]</li>
<li>[ICCV-2019] Weakly Aligned Cross-Modal Learning for Multispectral
Pedestrian Detection [<a
href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Weakly_Aligned_Cross-Modal_Learning_for_Multispectral_Pedestrian_Detection_ICCV_2019_paper.pdf">paper</a>]</li>
<li>[ICCV-2019] Discriminative Feature Transformation for Occluded
Pedestrian Detection [<a
href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Discriminative_Feature_Transformation_for_Occluded_Pedestrian_Detection_ICCV_2019_paper.pdf">paper</a>]</li>
<li>[ICCV-2019] Mask-Guided Attention Network for Occluded Pedestrian
Detection [<a
href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Pang_Mask-Guided_Attention_Network_for_Occluded_Pedestrian_Detection_ICCV_2019_paper.pdf">paper</a>]
[<a
href="https://github.com/Leotju/MGAN"><strong>code</strong></a>]</li>
<li>[TPAMI-2019] EuroCity Persons: A Novel Benchmark for Person
Detection in Traffic Scenes [<a
href="http://intelligent-vehicles.org/wp-content/uploads/2019/04/braun2019tpami_eurocity_persons.pdf">paper</a>]</li>
<li>[CVPR-2019 oral] Adaptive NMS: Refining Pedestrian Detection in a
Crowd [<a href="https://arxiv.org/abs/1904.02948">paper</a>]</li>
<li>[CVPR-2019] High-level Semantic Feature Detection:A New Perspective
for Pedestrian Detection [<a
href="https://arxiv.org/abs/1904.02948">paper</a>] [<a
href="https://github.com/liuwei16/CSP"><strong>code</strong></a>]</li>
<li>[CVPR-2019] SSA-CNN: Semantic Self-Attention CNN for Pedestrian
Detection</li>
<li>[CVPR-2019] Pedestrian Detection in Thermal Images using Saliency
Maps</li>
<li>[TIP-2018] Too Far to See? Not Really:- Pedestrian Detection with
Scale-Aware Localization Policy</li>
<li>[ECCV-2018] Bi-box Regression for Pedestrian Detection and Occlusion
Estimation [<a
href="https://github.com/rainofmine/Bi-box_Regression"><strong>code</strong></a>]</li>
<li>[ECCV-2018] Learning Efficient Single-stage Pedestrian Detectors by
Asymptotic Localization Fitting [<a
href="https://github.com/liuwei16/ALFNet"><strong>code</strong></a>]</li>
<li>[ECCV-2018] Graininess-Aware Deep Feature Learning for Pedestrian
Detection</li>
<li>[ECCV-2018] Occlusion-aware R-CNN: Detecting Pedestrians in a
Crowd</li>
<li>[ECCV-2018] Small-scale Pedestrian Detection Based on Somatic
Topology Localization and Temporal Feature Aggregation</li>
<li>[CVPR-2018] Improving Occlusion and Hard Negative Handling for
Single-Stage Pedestrian Detectors</li>
<li>[CVPR-2018] Occluded Pedestrian Detection Through Guided Attention
in CNNs</li>
<li>[CVPR-2018] Repulsion Loss: Detecting Pedestrians in a Crowd [<a
href="https://github.com/rainofmine/Repulsion_Loss"><strong>code</strong></a>]</li>
<li>[TCSVT-2018] Pushing the Limits of Deep CNNs for Pedestrian
Detection</li>
<li>[Trans Multimedia-2018] Scale-aware Fast R-CNN for Pedestrian
Detection</li>
<li>[TPAMI-2017] Jointly Learning Deep Features, Deformable Parts,
Occlusion and Classification for Pedestrian Detection</li>
<li>[BMVC-2017] PCN: Part and Context Information for Pedestrian
Detection with CNNs</li>
<li>[CVPR-2017] CityPersons: A Diverse Dataset for Pedestrian
Detection</li>
<li>[CVPR-2017] Learning Cross-Modal Deep Representations for Robust
Pedestrian Detection</li>
<li>[CVPR-2017] What Can Help Pedestrian Detection?</li>
<li>[ICCV-2017] Multi-label Learning of Part Detectors for Heavily
Occluded Pedestrian Detection</li>
<li>[ICCV-2017] Illuminating Pedestrians via Simultaneous Detection
&amp; Segmentation [<a
href="https://github.com/garrickbrazil/SDS-RCNN"><strong>code</strong></a>]</li>
<li>[TPAMI-2017] Towards Reaching Human Performance in Pedestrian
Detection</li>
<li>[Transactions on Multimedia-2017] Scale-Aware Fast R-CNN for
Pedestrian Detection</li>
<li>[CVPR-2016] Semantic Channels for Fast Pedestrian Detection</li>
<li>[CVPR-2016] How Far are We from Solving Pedestrian Detection?</li>
<li>![CVPR-2016] Pedestrian Detection Inspired by Appearance Constancy
and Shape Symmetry</li>
<li>![CVPR-2016] Semantic Channels for Fast Pedestrian Detection</li>
<li>![ECCV-2016] Is Faster R-CNN Doing Well for Pedestrian Detection?
[<a
href="https://github.com/zhangliliang/RPN_BF"><strong>code</strong></a>]</li>
<li>[CVPR-2015] Taking a Deeper Look at Pedestrians</li>
<li>![ICCV-2015] Learning Complexity-Aware Cascades for Deep Pedestrian
Detection</li>
<li>[ICCV-2015] Deep Learning Strong Parts for Pedestrian Detection</li>
<li>![ECCV-2014] Deep Learning of Scene-specific Classifier for
Pedestrian Detection</li>
<li>[CVPR-2013] Joint Deep Learning for Pedestrian Detection</li>
<li>[CVPR-2012] A Discriminative Deep Model for Pedestrian Detection
with Occlusion Handling</li>
<li>[CVPR-2010] Multi-Cue Pedestrian Classification With Partial
Occlusion Handling</li>
<li>[CVPR-2009] Pedestrian detection: A benchmark</li>
<li>[CVPR-2008] People-Tracking-by-Detection and
People-Detection-by-Tracking</li>
<li>[ECCV-2006] Human Detection Using Oriented Histograms of Flow and
Appearance</li>
<li>[CVPR-2005] Histograms of Oriented Gradients for Human
Detection</li>
</ul>
<h2 id="论文">论文</h2>
<h3
id="cvpr-2019-oral-adaptive-nms-refining-pedestrian-detection-in-a-crowd">[CVPR-2019
oral] Adaptive NMS: Refining Pedestrian Detection in a Crowd</h3>
<p><img src="./CVPR19_CSP_Adaptive_NMS.png"
alt="CVPR19_CSP_Adaptive_NMS" /> - paper:
https://arxiv.org/abs/1904.02948</p>
<h3
id="cvpr-2019-high-level-semantic-feature-detectiona-new-perspective-for-pedestrian-detection">[CVPR-2019]
High-level Semantic Feature Detection:A New Perspective for Pedestrian
Detection</h3>
<p><img src="./CVPR19_CSP_PedestrianDetection.png" alt="Alt text" /> -
paper: https://arxiv.org/abs/1904.02948 - github:
https://github.com/liuwei16/CSP</p>
<h3
id="cvpr-2019-ssa-cnn-semantic-self-attention-cnn-for-pedestrian-detection">[CVPR-2019]
SSA-CNN: Semantic Self-Attention CNN for Pedestrian Detection</h3>
<p><img src="./CVPR19_SSA-CNN.png" alt="Alt text" /> - paper:
https://arxiv.org/abs/1902.09080v1</p>
<h3
id="cvpr-2019-pedestrian-detection-in-thermal-images-using-saliency-maps">[CVPR-2019]
Pedestrian Detection in Thermal Images using Saliency Maps</h3>
<ul>
<li>paper: https://arxiv.org/abs/1904.06859</li>
</ul>
<h3
id="tip-2018-too-far-to-see-not-really-pedestrian-detection-with-scale-aware-localization-policy">[TIP-2018]
Too Far to See? Not Really: Pedestrian Detection with Scale-Aware
Localization Policy</h3>
<p><img src="./1533980426553.png" alt="Alt text| left | 300x0" /> -
paper: - project website: - slides: - github:</p>
<h3
id="transactions-on-multimedia-201８-scale-aware-fast-r-cnn-for-pedestrian-detection">[Transactions
on Multimedia-201８] Scale-Aware Fast R-CNN for Pedestrian
Detection</h3>
<figure>
<img src="./1533980383783.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper: https://ieeexplore.ieee.org/abstract/document/8060595/</li>
<li>project website:</li>
<li>slides:</li>
<li>github:</li>
</ul>
<h3
id="eccv-2018-bi-box-regression-for-pedestrian-detection-and-occlusion-estimation">[ECCV-2018]
Bi-box Regression for Pedestrian Detection and Occlusion Estimation</h3>
<p><img src="./ECCV2018-Bi-box_Regression_2.png"
alt="Alt text| left | 300x0" /> <img
src="./ECCV2018-Bi-box_Regression.png"
alt="Alt text| left | 300x0" /></p>
<ul>
<li>arxiv:</li>
<li>paper:http://openaccess.thecvf.com/content_ECCV_2018/papers/CHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdf</li>
<li>slides:</li>
<li>github: https://github.com/rainofmine/Bi-box_Regression</li>
</ul>
<h3
id="eccv-2018-learning-efficient-single-stage-pedestrian-detectors-by-asymptotic-localization-fitting">[ECCV-2018]
Learning Efficient Single-stage Pedestrian Detectors by Asymptotic
Localization Fitting</h3>
<figure>
<img
src="./ECCV2-18-Learning_Efficien_Single-stage_Pedestrian_Detectors.png"
alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:</li>
<li>paper:http://openaccess.thecvf.com/content_ECCV_2018/papers/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdf</li>
<li>project website:</li>
<li>slides:</li>
<li>github: https://github.com/liuwei16/ALFNet</li>
</ul>
<h3
id="eccv-2018-graininess-aware-deep-feature-learning-for-pedestrian-detection">[ECCV-2018]
Graininess-Aware Deep Feature Learning for Pedestrian Detection</h3>
<figure>
<img src="./ECCV2018-Graininess-Aware_Deep_Learning.png"
alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:</li>
<li>paper:http://openaccess.thecvf.com/content_ECCV_2018/papers/Chunze_Lin_Graininess-Aware_Deep_Feature_ECCV_2018_paper.pdf</li>
<li>project website:</li>
<li>slides:</li>
<li>github:</li>
</ul>
<h3
id="eccv-2018-occlusion-aware-r-cnn-detecting-pedestrians-in-a-crowd">[ECCV-2018]
Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</h3>
<figure>
<img src="./ECCV2018-Occlusion-aware_R-CNN.png"
alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:http://arxiv.org/abs/1807.08407</li>
<li>project website:</li>
<li>slides:</li>
<li>github:</li>
</ul>
<h3
id="eccv-2018-small-scale-pedestrian-detection-based-on-somatic-topology-localization-and-temporal-feature-aggregation">[ECCV-2018]
Small-scale Pedestrian Detection Based on Somatic Topology Localization
and Temporal Feature Aggregation</h3>
<figure>
<img src="./1533979932529.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:https://arxiv.org/abs/1807.01438</li>
<li>project website:</li>
<li>slides:</li>
<li>github:</li>
</ul>
<h3
id="cvpr-2018-improving-occlusion-and-hard-negative-handling-for-single-stage-pedestrian-detectors">[CVPR-2018]
Improving Occlusion and Hard Negative Handling for Single-Stage
Pedestrian Detectors</h3>
<figure>
<img src="./1533980803719.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:</li>
<li>paper:
http://vision.snu.ac.kr/projects/partgridnet/data/noh_2018.pdf</li>
<li>project website: http://vision.snu.ac.kr/projects/partgridnet/</li>
<li>slides:</li>
<li>github:</li>
</ul>
<h3
id="cvpr-2018-occluded-pedestrian-detection-through-guided-attention-in-cnns">[CVPR-2018]
Occluded Pedestrian Detection Through Guided Attention in CNNs</h3>
<figure>
<img src="./1533980145178.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:</li>
<li>paper:
http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.pdf</li>
<li>project website:</li>
<li>slides:</li>
<li>github:</li>
</ul>
<h3
id="cvpr-2018-repulsion-loss-detecting-pedestrians-in-a-crowd">[CVPR-2018]
Repulsion Loss: Detecting Pedestrians in a Crowd</h3>
<figure>
<img src="./1528195001788.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv:http://arxiv.org/abs/1711.07752</li>
<li>project website:</li>
<li>slides:</li>
<li>github:</li>
<li>blog: https://zhuanlan.zhihu.com/p/41288115</li>
</ul>
<h3
id="tpami-2017-jointly-learning-deep-features-deformable-parts-occlusion-and-classification-for-pedestrian-detection">[TPAMI-2017]
Jointly Learning Deep Features, Deformable Parts, Occlusion and
Classification for Pedestrian Detection</h3>
<figure>
<img src="./1537261066815.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper: https://ieeexplore.ieee.org/abstract/document/8008790/</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="bmvc-2017-pcn-part-and-context-information-for-pedestrian-detection-with-cnns">[BMVC-2017]
PCN: Part and Context Information for Pedestrian Detection with
CNNs</h3>
<figure>
<img src="./1533980559400.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv: https://arxiv.org/abs/1804.044838</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="cvpr-2017-citypersons-a-diverse-dataset-for-pedestrian-detection">[CVPR-2017]
CityPersons: A Diverse Dataset for Pedestrian Detection</h3>
<figure>
<img src="./1528194369562.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv: http://arxiv.org/abs/1702.05693</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<hr />
<h3
id="cvpr-2017-learning-cross-modal-deep-representations-for-robust-pedestrian-detection">[CVPR-2017]
Learning Cross-Modal Deep Representations for Robust Pedestrian
Detection</h3>
<figure>
<img src="./1528194560698.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv: https://arxiv.org/abs/1704.02431</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<p><img src="./1528194591022.png" alt="Alt text" /> <img
src="./1528194606094.png" alt="Alt text" /></p>
<h3 id="cvpr-2017-what-can-help-pedestrian-detection">[CVPR-2017] What
Can Help Pedestrian Detection?</h3>
<ul>
<li>arxiv: https://arxiv.org/abs/1704.02431</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="tpami-2017-towards-reaching-human-performance-in-pedestrian-detection">[TPAMI-2017]
Towards Reaching Human Performance in Pedestrian Detection</h3>
<ul>
<li>paper: http://ieeexplore.ieee.org/document/7917260/</li>
<li>arxiv:</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="iccv-2017-multi-label-learning-of-part-detectors-for-heavily-occluded-pedestrian-detection">[ICCV-2017]
Multi-label Learning of Part Detectors for Heavily Occluded Pedestrian
Detection</h3>
<ul>
<li>paper:
http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Multi-Label_Learning_of_ICCV_2017_paper.pdf</li>
<li>arxiv:</li>
<li>project website:</li>
<li>slides:</li>
</ul>
<h3
id="iccv-2017illuminating-pedestrians-via-simultaneous-detection-segmentation">[ICCV-2017]Illuminating
Pedestrians via Simultaneous Detection &amp; Segmentation</h3>
<figure>
<img src="http://cvlab.cse.msu.edu/images/teasers/pedestrian-intro.png"
alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>arxiv: https://arxiv.org/abs/1706.08564</li>
<li>project website:
http://cvlab.cse.msu.edu/project-pedestrian-detection.html</li>
<li>slides:</li>
<li>github caffe: https://github.com/garrickbrazil/SDS-RCNN</li>
</ul>
<h3
id="cvpr-2016-semantic-channels-for-fast-pedestrian-detection">[CVPR-2016]
Semantic Channels for Fast Pedestrian Detection</h3>
<figure>
<img src="./1528195250768.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper:
https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Costea_Semantic_Channels_for_CVPR_2016_paper.pdf</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="cvpr-2016-how-far-arewe-from-solving-pedestrian-detection">[CVPR-2016]
How Far areWe from Solving Pedestrian Detection?</h3>
<ul>
<li>paper:
https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S06-29.pdf</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="iccv-2015-deep-learning-strong-parts-for-pedestrian-detection">[ICCV-2015]
Deep Learning Strong Parts for Pedestrian Detection</h3>
<figure>
<img src="./1537260670049.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper:
https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Tian_Deep_Learning_Strong_ICCV_2015_paper.htmler.html</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="cvpr-2013-joint-deep-learning-for-pedestrian-detection-wanli">[CVPR-2013]
Joint Deep Learning for Pedestrian Detection Wanli</h3>
<figure>
<img src="./1537260505221.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper:
https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Ouyang_Joint_Deep_Learning_2013_ICCV_paper.html</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="cvpr-2012-a-discriminative-deep-model-for-pedestrian-detection-with-occlusion-handling">[CVPR-2012]
A Discriminative Deep Model for Pedestrian Detection with Occlusion
Handling</h3>
<figure>
<img src="./1537260310332.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper: http://mmlab.ie.cuhk.edu.hk/pdf/ouyangWcvpr2012.pdf</li>
<li>paper: https://ieeexplore.ieee.org/abstract/document/6248062/</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h3
id="cvpr-2010-multi-cue-pedestrian-classification-with-partial-occlusion-handling">[CVPR-2010]
Multi-Cue Pedestrian Classification With Partial Occlusion Handling</h3>
<figure>
<img src="./1537260117170.png" alt="Alt text| left | 300x0" />
<figcaption aria-hidden="true">Alt text| left | 300x0</figcaption>
</figure>
<ul>
<li>paper: https://ieeexplore.ieee.org/abstract/document/5540111/</li>
<li>project website:</li>
<li>slides:</li>
<li>github caffe:</li>
</ul>
<h2 id="行人检测数据集">行人检测数据集</h2>
<h3 id="citypersons">CityPersons</h3>
<figure>
<img src="./1534569661113.png" alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<p>CityPersons数据集是在Cityscapes数据集基础上建立的，使用了Cityscapes数据集的数据，对一些类别进行了精确的标注。该数据集是在[CVPR-2017]
CityPersons: A Diverse Dataset for Pedestrian
Detection这篇论文中提出的，更多细节可以通过阅读该论文了解。</p>
<p>上图中左侧是行人标注，右侧是原始的CityScapes数据集。</p>
<ul>
<li><a
href="https://bitbucket.org/shanshanzhang/citypersons"><strong>标注和评估文件</strong></a></li>
<li><a
href="https://www.cityscapes-dataset.com/"><strong>数据集下载</strong></a></li>
</ul>
<p>文件格式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#评测文件</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/coco.py</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/eval_demo.py</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/evaluation/eval_script/eval_MR_multisetup.py</span><br><span class="line"></span><br><span class="line">#注释文件</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/anno_train.mat</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/anno_val.mat</span><br><span class="line">$/Cityscapes/shanshanzhang-citypersons/annotations/README.txt</span><br><span class="line">#图片数据</span><br><span class="line"></span><br><span class="line">$/Cityscapes/leftImg8bit/train/*</span><br><span class="line">$/Cityscapes/leftImg8bit/val/*</span><br><span class="line">$/Cityscapes/leftImg8bit/test/*</span><br></pre></td></tr></table></figure>
<p>注释文件格式 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">CityPersons annotations</span><br><span class="line">(1) data structure:</span><br><span class="line">    one image per cell</span><br><span class="line">    in each cell, there are three fields: city_name; im_name; bbs (bounding box annotations)</span><br><span class="line"></span><br><span class="line">(2) bounding box annotation format:</span><br><span class="line">　　 one object instance per row:</span><br><span class="line">　　 [class_label, x1,y1,w,h, instance_id, x1_vis, y1_vis, w_vis, h_vis]</span><br><span class="line"></span><br><span class="line">(3) class label definition:</span><br><span class="line">　 class_label =0: ignore regions (fake humans, e.g. people on posters, reflections etc.)</span><br><span class="line">    class_label =1: pedestrians</span><br><span class="line">    class_label =2: riders</span><br><span class="line">    class_label =3: sitting persons</span><br><span class="line">    class_label =4: other persons with unusual postures</span><br><span class="line">    class_label =5: group of people</span><br><span class="line"></span><br><span class="line">(4) boxes:</span><br><span class="line">　　visible boxes [x1_vis, y1_vis, w_vis, h_vis] are automatically generated from segmentation masks;</span><br><span class="line">      (x1,y1) is the upper left corner.</span><br><span class="line">      if class_label==1 or 2</span><br><span class="line">        [x1,y1,w,h] is a well-aligned bounding box to the full body ;</span><br><span class="line">      else</span><br><span class="line">        [x1,y1,w,h] = [x1_vis, y1_vis, w_vis, h_vis];</span><br></pre></td></tr></table></figure></p>
<h3 id="caltech">Caltech</h3>
<figure>
<img src="1517407508293.png" alt="caltech" />
<figcaption aria-hidden="true">caltech</figcaption>
</figure>
<ul>
<li><a
href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/"><strong>Caltech官网</strong></a>
更所细节请阅读这篇论文， <a
href="http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/PAMI12pedestrians.pdf">[TAPAMI-2012]
Pedestrian Detection: An Evaluation of the State of the Art</a></li>
</ul>
<figure>
<img src="./1534570096814.png" alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<h3 id="kitti">KITTI</h3>
<figure>
<img src="./1534569869602.png" alt="Alt text" />
<figcaption aria-hidden="true">Alt text</figcaption>
</figure>
<ul>
<li><a
href="http://www.cvlibs.net/datasets/kitti/"><strong>KITTI官网</strong></a></li>
</ul>
<h3 id="eurocity">EuroCity</h3>
<p><a
href="https://eurocity-dataset.tudelft.nl/eval/overview/statistics">EuroCity
官网</a></p>
<p><a
href="http://intelligent-vehicles.org/wp-content/uploads/2019/04/braun2019tpami_eurocity_persons.pdf">EuroCity
Paper</a></p>
<ul>
<li>[TPAMI-2019] EuroCity Persons: A Novel Benchmark for Person
Detection in Traffic Scenes</li>
</ul>
<p>With over 238200 person instances manually labeled in over 47300
images, EuroCity Persons is nearly one order of magnitude larger than
person datasets used previously for benchmarking. Diversity is gained by
recording this dataset throughout Europe.</p>
<figure>
<img src="./eurocity-01.png" alt="EuroCity-01" />
<figcaption aria-hidden="true">EuroCity-01</figcaption>
</figure>
<figure>
<img src="./eurocity-02.png" alt="EuroCity-02" />
<figcaption aria-hidden="true">EuroCity-02</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Object Class</th>
<th style="text-align: center;"># objects (day)</th>
<th style="text-align: center;"># objects (night)</th>
<th style="text-align: center;"># objects (sum)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Pedestrian</td>
<td style="text-align: center;">183004</td>
<td style="text-align: center;">35309</td>
<td style="text-align: center;">218313</td>
</tr>
<tr class="even">
<td style="text-align: center;">Rider</td>
<td style="text-align: center;">18216</td>
<td style="text-align: center;">1564</td>
<td style="text-align: center;">19780</td>
</tr>
</tbody>
</table>
<h3 id="crowdhuman">CrowdHuman</h3>
<p><a href="http://www.crowdhuman.org/">CrowdHuman 主页</a></p>
<p><a href="https://arxiv.org/abs/1805.00123">CrowdHuman Paper</a></p>
<figure>
<img src="./crowdhuman-20190918-01.png" alt="CrowdHuman-20190918-01" />
<figcaption aria-hidden="true">CrowdHuman-20190918-01</figcaption>
</figure>
<figure>
<img src="./crowdhuman-20190918-02.png" alt="CrowdHuman-20190918-02" />
<figcaption aria-hidden="true">CrowdHuman-20190918-02</figcaption>
</figure>
<figure>
<img src="./crowdhuman-20190918-03.png" alt="CrowdHuman-20190918-03" />
<figcaption aria-hidden="true">CrowdHuman-20190918-03</figcaption>
</figure>
<h2 id="性能比较">性能比较</h2>
<p>数据来自 <a
href="https://bitbucket.org/shanshanzhang/citypersons/src/default/">CityPersons</a>
官网。</p>
<table>
<colgroup>
<col style="width: 20%" />
<col style="width: 17%" />
<col style="width: 23%" />
<col style="width: 27%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">MR (Reasonable)</th>
<th style="text-align: center;">MR (Reasonable_small)</th>
<th style="text-align: center;">MR (Reasonable_occ=heavy)</th>
<th style="text-align: center;">MR (All)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">YT-PedDet</td>
<td style="text-align: center;">8.41%</td>
<td style="text-align: center;">10.60%</td>
<td style="text-align: center;">37.88%</td>
<td style="text-align: center;">37.22%</td>
</tr>
<tr class="even">
<td style="text-align: center;">STNet</td>
<td style="text-align: center;">9.78%</td>
<td style="text-align: center;">10.95%</td>
<td style="text-align: center;">36.16%</td>
<td style="text-align: center;">31.36%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">DVRNet</td>
<td style="text-align: center;">10.99%</td>
<td style="text-align: center;">15.68%</td>
<td style="text-align: center;">43.77%</td>
<td style="text-align: center;">41.48%</td>
</tr>
<tr class="even">
<td style="text-align: center;">HBA-RCNN</td>
<td style="text-align: center;">11.06%</td>
<td style="text-align: center;">14.77%</td>
<td style="text-align: center;">43.61%</td>
<td style="text-align: center;">39.54%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">OR-CNN</td>
<td style="text-align: center;">11.32%</td>
<td style="text-align: center;">14.19%</td>
<td style="text-align: center;">51.43%</td>
<td style="text-align: center;">40.19%</td>
</tr>
<tr class="even">
<td style="text-align: center;">Repultion Loss</td>
<td style="text-align: center;">11.48%</td>
<td style="text-align: center;">15.67%</td>
<td style="text-align: center;">52.59%</td>
<td style="text-align: center;">39.17%</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Adapted FasterRCNN</td>
<td style="text-align: center;">12.97%</td>
<td style="text-align: center;">37.24%</td>
<td style="text-align: center;">50.47%</td>
<td style="text-align: center;">43.86%</td>
</tr>
<tr class="even">
<td style="text-align: center;">MS-CNN</td>
<td style="text-align: center;">13.32%</td>
<td style="text-align: center;">15.86%</td>
<td style="text-align: center;">51.88%</td>
<td style="text-align: center;">39.94%</td>
</tr>
</tbody>
</table>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Pedestrian-Detection/" rel="tag"># Pedestrian Detection</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/08/14/Keras-Tutorial/" rel="prev" title="Keras Tutorial">
                  <i class="fa fa-angle-left"></i> Keras Tutorial
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2018/09/02/CornerNet-Detection-Objects-as-Paired-Keypoints/" rel="next" title="CornerNet: Detection Objects as Paired Keypoints">
                  CornerNet: Detection Objects as Paired Keypoints <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Tianliang Zhang</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"xingkongliang","repo":"starlg-cn-gitment","client_id":"Ov23li0otPFcEzcybypu","client_secret":"bbab6cb791d07a668f56cba28f79d241beb0b348","admin_user":"xingkongliang","distraction_free_mode":false,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"2657e3f88bd3c324404475abe593e3ad"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
