<!DOCTYPE html>
<html lang="default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.starlg.cn","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Deformable DETR 缓解了 DETR 收敛慢和高计算复杂性的问题。它组合了 deformable 卷积的稀疏空间采样特性和 Transformer 的相关性的建模能力。论文提出的 deformable attention 模块将一小组采样位置作为所有特征图像素中重要的关键元素的预过滤器。">
<meta property="og:type" content="article">
<meta property="og:title" content="Deformable DETR">
<meta property="og:url" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/index.html">
<meta property="og:site_name" content="Tianliang">
<meta property="og:description" content="Deformable DETR 缓解了 DETR 收敛慢和高计算复杂性的问题。它组合了 deformable 卷积的稀疏空间采样特性和 Transformer 的相关性的建模能力。论文提出的 deformable attention 模块将一小组采样位置作为所有特征图像素中重要的关键元素的预过滤器。">
<meta property="og:locale">
<meta property="og:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure1.png">
<meta property="og:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure2.png">
<meta property="og:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure3.png">
<meta property="og:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Table1.png">
<meta property="og:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Table3.png">
<meta property="og:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Table4.png">
<meta property="article:published_time" content="2021-11-24T02:33:31.000Z">
<meta property="article:modified_time" content="2022-05-30T14:16:36.000Z">
<meta property="article:author" content="Tianliang Zhang">
<meta property="article:tag" content="Object Detection">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.starlg.cn/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure1.png">


<link rel="canonical" href="https://www.starlg.cn/2021/11/24/Deformable-DETR/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"default","comments":true,"permalink":"https://www.starlg.cn/2021/11/24/Deformable-DETR/","path":"2021/11/24/Deformable-DETR/","title":"Deformable DETR"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Deformable DETR | Tianliang</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PLDYM9BF5R"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-PLDYM9BF5R","only_pageview":false,"measure_protocol_api_secret":null}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Tianliang</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="https://www.starlg.cn/TianliangZhang/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container">
  <div class="algolia-stats"><hr></div>
  <div class="algolia-hits"></div>
  <div class="algolia-pagination"></div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9E%E9%A1%BE-transformer-%E5%92%8C-detr"><span class="nav-number">2.</span> <span class="nav-text">回顾 Transformer 和 DETR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#multi-head-attention-in-transformers"><span class="nav-number">2.1.</span> <span class="nav-text">Multi-Head Attention in
Transformers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#detr"><span class="nav-number">2.2.</span> <span class="nav-text">DETR</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#method"><span class="nav-number">3.</span> <span class="nav-text">Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ddformable-transformer-for-end-to-end-object-detection"><span class="nav-number">3.1.</span> <span class="nav-text">Ddformable
Transformer for End-To-End Object Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#deformable-attention-module"><span class="nav-number">3.1.1.</span> <span class="nav-text">Deformable Attention Module</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#multi-scale-deformable-attention-module"><span class="nav-number">3.1.2.</span> <span class="nav-text">Multi-scale Deformable
Attention Module</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deformable-transformer-encoder"><span class="nav-number">3.1.3.</span> <span class="nav-text">Deformable Transformer
Encoder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deformable-transformer-decoder"><span class="nav-number">3.1.4.</span> <span class="nav-text">Deformable Transformer
Decoder</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%94%B9%E8%BF%9B-%E5%92%8C-%E5%8F%98%E4%BD%93"><span class="nav-number">3.2.</span> <span class="nav-text">其他改进 和 变体</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">4.</span> <span class="nav-text">实验结果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E"><span class="nav-number">5.</span> <span class="nav-text">论文中的符号说明</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Tianliang Zhang"
      src="https://avatars1.githubusercontent.com/u/8827798?v=3&s=460">
  <p class="site-author-name" itemprop="name">Tianliang Zhang</p>
  <div class="site-description" itemprop="description">Writing is the best form of thinking!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/xingkongliang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xingkongliang" rel="noopener me" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:tianliangjay@gmail.com" title="E-Mail → mailto:tianliangjay@gmail.com" rel="noopener me" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://www.zhihu.com/people/xingkong_liang" title="知乎 → http:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;xingkong_liang" rel="noopener me" target="_blank">知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://weibo.com/1863221531" title="微博 → http:&#x2F;&#x2F;weibo.com&#x2F;1863221531" rel="noopener me" target="_blank"><i class="weibo fa-fw"></i>微博</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          Links
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://codesolve.online/" title="https:&#x2F;&#x2F;codesolve.online" rel="noopener" target="_blank">LeetCode解题指南</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://easyielts.cn/" title="https:&#x2F;&#x2F;easyielts.cn" rel="noopener" target="_blank">雅思题库和范例</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="default">
    <link itemprop="mainEntityOfPage" href="https://www.starlg.cn/2021/11/24/Deformable-DETR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/8827798?v=3&s=460">
      <meta itemprop="name" content="Tianliang Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tianliang">
      <meta itemprop="description" content="Writing is the best form of thinking!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Deformable DETR | Tianliang">
      <meta itemprop="description" content="Deformable DETR 缓解了 DETR 收敛慢和高计算复杂性的问题。它组合了 deformable 卷积的稀疏空间采样特性和 Transformer 的相关性的建模能力。论文提出的 deformable attention 模块将一小组采样位置作为所有特征图像素中重要的关键元素的预过滤器。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Deformable DETR
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-24 12:33:31" itemprop="dateCreated datePublished" datetime="2021-11-24T12:33:31+10:00">2021-11-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-31 00:16:36" itemprop="dateModified" datetime="2022-05-31T00:16:36+10:00">2022-05-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Object-Detection/" itemprop="url" rel="index"><span itemprop="name">Object Detection</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

            <div class="post-description">Deformable DETR 缓解了 DETR 收敛慢和高计算复杂性的问题。它组合了 deformable 卷积的稀疏空间采样特性和 Transformer 的相关性的建模能力。论文提出的 deformable attention 模块将一小组采样位置作为所有特征图像素中重要的关键元素的预过滤器。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>Paper：https://arxiv.org/abs/2010.04159</p>
<p>Code：https://github.com/fundamentalvision/Deformable-DETR</p>
<h2 id="介绍">介绍</h2>
<p>最近提出的 DETR
消除了目标检测中很多手工设计的组件，然而降低了精度。除此之外，由于受到
Tranformer attention
模块在处理图片特征的限制，导致它收敛很慢，并且限制了特征空间分辨率。</p>
<p>为了解决上述问题，论文提出了 Deformable DETR，它的 <strong>attention
模块</strong>仅仅关注 <strong>参考点
附近的一组关键采样点</strong>。Deformable DETR 可以获得比 DETR
更好的性能（尤其是在小物体上），并且训练次数减少了 10 倍。</p>
<img src="/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure1.png" class="" title="Deformable DETR object detector">
<p>DETR存在的两个问题：（1）比起现存的目标检测器，它的收敛要求太长时间的训练周期。例如，在COCO数据集上，DETR
需要 500 epochs 才能收敛，而这大约比 Faster RCNN 慢了 10~20
倍。（2）DETR
在检测小目标上存在较低的性能。当前的检测器通常利用多尺度特征，这这些特征上小目标可以从高分辨率特征上被检测。然而，高分辨率的特征图给
DETR 带来的严重的计算代价。 上述问题主要归因于 Transformer
组件在处理图像特征图方面的不足。在初始化的时候，attention modules
将几乎统一的注意力权重投射到特征图中的所有像素。让学习注意力权重专注于稀疏有意义的位置，长时间的训练周期是必要的。
另一方面，Transformer 编码器中的注意力权重计算是像素数的平方计算量。
因此，处理高分辨率特征图具有非常高的计算和内存复杂性。</p>
<p>在图片领域，deformable
卷积是一种强有力且高效的关注稀疏空间位置的机制。它可以天然的避免上述提到的问题。然而它缺乏元素关系建模机制，这是DETR成功的关键。</p>
<p>在这篇论文中，作者提出 Deformable DETR，它缓解了 DETR
收敛慢和高计算复杂性的问题。它组合了 deformable 卷积的稀疏空间采样特性和
Transformer 的相关性的建模能力。论文提出的 deformable attention
模块将一小组采样位置作为所有特征图像素中重要的关键元素的预过滤器。</p>
<p>由于其快速收敛以及计算和内存效率，Deformable DETR
为我们开辟了利用端到端对象检测器变体的可能性。
作者探索了一种简单有效的迭代边界框细化（iterative bounding box
refinement）机制来提高检测性能。 论文还尝试了一个 two-stage Deformable
DETR，其中 region proposal 也是由 Deformable DETR
的变体生成的，它们被进一步输入 decoder 以进行 iterative bounding box
refinement。</p>
<h2 id="回顾-transformer-和-detr">回顾 Transformer 和 DETR</h2>
<h3 id="multi-head-attention-in-transformers">Multi-Head Attention in
Transformers</h3>
<p>Transformers
是针对机器翻译任务设计的一种基于注意力机制的网络结构。给一个 query
元素（例如，在一个输出句子中的一个目标单词）和一组 key
元素（例如，在输入句子中的原单词），multi-head attention
模块根据注意力权重自适应地汇聚关键信息，这个注意力权重可以测量 query-key
对
质检的一致性。为了允许让模型从不同表示子空间和不同位置中关注信息，不同
attention heads 的输出是使用学到的权重线性聚合的结果。Multi-head
attention 特征可以计算为：</p>
<p><span class="math display">\[
\operatorname{MultiHeadAttn}\left(\boldsymbol{z}_{q},
\boldsymbol{x}\right)=\sum_{m=1}^{M} \boldsymbol{W}_{m}\left[\sum_{k \in
\Omega_{k}} A_{m q k} \cdot \boldsymbol{W}_{m}^{\prime}
\boldsymbol{x}_{k}\right]
\]</span></p>
<p><span class="math inline">\(q \in \Omega_{q}\)</span> 表示 一个 query
元素的索引，其特征表示为 <span class="math inline">\(z_q \in
\mathbb{R}^{C}\)</span></p>
<p><span class="math inline">\(k \in \Omega_{k}\)</span> 表示一个 key
元素的索引，其特征表示为 <span class="math inline">\(x_k \in
\mathbb{R}^C\)</span></p>
<p><span class="math inline">\(C\)</span> 特征的维度</p>
<p><span class="math inline">\(M\)</span> attention head 的数量，<span
class="math inline">\(m\)</span> 是 attention head 的索引</p>
<p><span class="math inline">\(\mathbf{W}_{m}^{\prime} \in
\mathbb{R}^{C_{v}\times C}\)</span> 和 <span
class="math inline">\(\mathbf{W}_{m} \in \mathbb{R}^{C_{v}\times
C}\)</span> 是可学习的权重，并且 <span class="math inline">\(C_{v} =
C/M\)</span></p>
<p><span class="math inline">\(A_{m q k} \propto \exp
\left\{\frac{\mathbf{z}_{q}^{T} \mathbf{U}_{m}^{T} \mathbf{V}_{m}
\mathbf{x}_{k}}{\sqrt{C_{v}}}\right\}\)</span> 是 attention
权重，它被归一化，并且 <span class="math inline">\(\sum_{k\in
\Omega_{k}} A_{mqk}=1\)</span> 其中 <span
class="math inline">\(\mathbf{U}_{m}\)</span> 和 <span
class="math inline">\(\mathbf{V}_{m}\)</span> 也是可学习的权重。</p>
<p>为了消除不同空间位置的歧义，表示特征 <span
class="math inline">\(x_q\)</span> 和 <span
class="math inline">\(x_k\)</span> 通常是和 positional embedding
的串联/求和。</p>
<h3 id="detr">DETR</h3>
<p>对于 DETR 中的 Transformer encoder，query 和 key
元素都是特征图中的像素。输入是 ResNet 特征图（带有编码的 positional
embeddings）。让 <span class="math inline">\(H\)</span> 和 <span
class="math inline">\(W\)</span> 分别表示特征图的高度和宽度。
self-attention 的计算复杂度为 <span class="math inline">\(O(H^2 W^2
C)\)</span> ，随空间大小呈二次方增长。</p>
<p>对于 DETR 中的 Transformer dncoder，输入包括来自 encoder 的特征图和
由可学习位置嵌入（例如，N = 100）表示的 N object queries。decoder
中有两种注意力模块，即 cross-attention 和 self-attention 模块。在
cross-attention 模块中，object query 从特征图中提取特征。query
元素属于object queries，key 元素属于encoder 的输出特征图。其中，<span
class="math inline">\(N_q = N\)</span>，<span class="math inline">\(N_k
= H \times W\)</span>，交叉注意力的复杂度为 <span
class="math inline">\(O(HWC^2 +
NHWC)\)</span>。复杂性随着特征图的空间大小线性增长。在 self-attention
模块中，object queries 相互交互，以捕获它们的关系。 query 和 key
元素都是 object queries。 其中，<span class="math inline">\(N_q = N_k =
N\)</span>，self-attention 模块的复杂度为 <span
class="math inline">\(O(2NC^2 +N^2 C)\)</span>。
中等数量的对象查询的复杂性是可以接受的。</p>
<p>这主要是因为处理图像特征的注意力模块很难训练。
例如，在初始化时，cross-attention
模块几乎对整个特征图具有平均注意力。而在训练结束时，attention maps
被学习到非常稀疏，只关注对象的外轮廓（extremities）。 似乎 DETR
需要很长的训练才能学习注意力图的如此显着的变化。</p>
<h2 id="method">Method</h2>
<h3
id="ddformable-transformer-for-end-to-end-object-detection">Ddformable
Transformer for End-To-End Object Detection</h3>
<img src="/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure2.png" class="" title="deformable attention module">
<h4 id="deformable-attention-module">Deformable Attention Module</h4>
<p><span class="math display">\[
\operatorname{DeformAttn}\left(\boldsymbol{z}_{q}, \boldsymbol{p}_{q},
\boldsymbol{x}\right)=\sum_{m=1}^{M}
\boldsymbol{W}_{m}\left[\sum_{k=1}^{K} A_{m q k} \cdot
\boldsymbol{W}_{m}^{\prime}
\boldsymbol{x}\left(\boldsymbol{p}_{q}+\Delta \boldsymbol{p}_{m q
k}\right)\right]
\]</span></p>
<p>这里 <span class="math inline">\(m\)</span> attention head
的索引，<span class="math inline">\(k\)</span> 采样 keys 的索引，<span
class="math inline">\(K\)</span> 是总采样的 key 的数量 <span
class="math inline">\(（K \ll HW）\)</span>。<span
class="math inline">\(\Delta p_{mqk}\)</span> 和 <span
class="math inline">\(A_{mqk}\)</span> 是采样的偏置和在 <span
class="math inline">\(m^{th}\)</span> attention head 上的 <span
class="math inline">\(k^{th}\)</span> 采样点的 attention weight。</p>
<h4 id="multi-scale-deformable-attention-module">Multi-scale Deformable
Attention Module</h4>
<p><span class="math display">\[
\operatorname{MSDeformAttn}\left(\boldsymbol{z}_{q},
\hat{\boldsymbol{p}}_{q},\left\{\boldsymbol{x}^{l}\right\}_{l=1}^{L}\right)=\sum_{m=1}^{M}
\boldsymbol{W}_{m}\left[\sum_{l=1}^{L} \sum_{k=1}^{K} A_{m l q k} \cdot
\boldsymbol{W}_{m}^{\prime}
\boldsymbol{x}^{l}\left(\phi_{l}\left(\hat{\boldsymbol{p}}_{q}\right)+\Delta
\boldsymbol{p}_{m l q k}\right)\right]
\]</span></p>
<h4 id="deformable-transformer-encoder">Deformable Transformer
Encoder</h4>
<p>由于提出的 multi-scale deformable attention
可以再不同多尺度特征层上交换信息，所以没有使用 FPN 结构。</p>
<p>在 encoder 中 multi-scale deformable attention
模块的应用中，输出是与输入具有相同分辨率的多尺度特征图。key 和 query
元素都是来自多尺度特征图的像素。对于每一个 query
像素，这个参考点（reference point）就是它自己。为了识别每个 query
像素位于哪个特征级别，除了 positional embedding
之外，我们还向特征表示中添加了 a scale-level embedding，表示为 <span
class="math inline">\(e_l\)</span>。与固定编码的 positional embedding
不同，scale-level embedding <span
class="math inline">\(\{e_l\}^L_l=1\)</span>
是随机初始化并与网络联合训练。</p>
<h4 id="deformable-transformer-decoder">Deformable Transformer
Decoder</h4>
<p>decoder 中有 cross-attention 和 self-attention
模块。这两种注意力模块的 query 元素都是 object queries。在
cross-attention 模块中，object queries 从特征图中提取特征，其中 key
元素是来自 encoder 的输出特征图。在 self-attention 模块中，object
queries 相互交互，其中 key 元素是 object queries。由于我们提出的
deformable attantion 模块是为处理卷积特征图作为 key
元素而设计的，因此我们仅将每个 cross-attention 模块替换为 multi-scale
deformable attention 模块，而保持 self-attention 模块不变。对于每个
object query，参考点 <span class="math inline">\(\hat p_q\)</span>
的二维归一化坐标是从其 object query embedding 中通过可学习的线性投影和
<span class="math inline">\(\mathrm{sigmoid}\)</span> 函数预测的。</p>
<p>因为 multi-scale deformable attention 模块提取参考点（reference
point）周围的图像特征，我们让检测头将边界框预测为相对偏移，也就是参考点进一步降低优化难度。
参考点用作框中心的初始猜测。检测头预测相对偏移，也就是参考点。这样，学习到的
decoder attention
将与预测的边界框有很强的相关性，这也加速了训练收敛。</p>
<p>通过在 DETR 中用 deformable attention 模块替换 Transformer attention
模块，我们建立了一个高效且快速收敛的检测系统，称为 Deformable DETR。</p>
<h3 id="其他改进-和-变体">其他改进 和 变体</h3>
<p>Iterative Bounding Box Refinemen</p>
<p>Two-Stage Deformable DETR</p>
<h2 id="实验结果">实验结果</h2>
<img src="/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Figure3.png" class="" title="Convergence curves of Deformable DETR and DETR-DC5.">
<p>由上图可以看出，Deformable DETR 明显提升了训练速度。</p>
<img src="/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Table1.png" class="">
<img src="/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Table3.png" class="">
<h2 id="论文中的符号说明">论文中的符号说明</h2>
<img src="/2021/11/24/Deformable-DETR/20211124_Deformable_DETR_Table4.png" class="" title="Table 4">

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Object-Detection/" rel="tag"># Object Detection</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/07/13/Beancount-01/" rel="prev" title="复式记账 Beancount 使用">
                  <i class="fa fa-angle-left"></i> 复式记账 Beancount 使用
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/12/27/Efficient-DETR/" rel="next" title="Efficient DETR">
                  Efficient DETR <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Tianliang Zhang</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/algoliasearch/4.23.3/algoliasearch-lite.umd.js" integrity="sha256-1QNshz86RqXe/qsCBldsUu13eAX6n/O98uubKQs87UI=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/instantsearch.js/4.67.0/instantsearch.production.min.js" integrity="sha256-TW7D3X/i/W+RUgEeDppEnFT2ixv5lzplKH0c58D92dY=" crossorigin="anonymous"></script><script src="/js/third-party/search/algolia-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"xingkongliang","repo":"starlg-cn-gitment","client_id":"Ov23li0otPFcEzcybypu","client_secret":"bbab6cb791d07a668f56cba28f79d241beb0b348","admin_user":"xingkongliang","distraction_free_mode":false,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"a397703fe8f202ff9535ed16cc74ee71"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
